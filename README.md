# Code repository for "An alternative to the F-test with enhanced power in sparse linear models" by Paulson, Sengupta, and Janson (2025)

This repository contains the source code for implementing all of the testing procedures and reproducing all of the figures presented in the [paper](https://arxiv.org/abs/2406.18390). The L-test is a new procedure for testing the signifiance of a subset of covariates (i.e. $H_0: \beta_{1:k} = 0$) in a Gaussian linear model with $n \geq d$. Under the same assumptions as the classical F-test, the L-test delivers the exact same statistical guarantees while achieving higher power when the nuisance parameters $\beta_{-1:k}$ are sparse.

## Example of methods application
The file `tests_main.py` contains the main methods introduced in the paper, including the L-test, its computationally efficient variant the R-test, and the oracle test, which is used to provide power intuition. The file `utils.py` contains helper functions to implement these main methods, and `tests_support.py` contains additional tests considered in the paper. Below, we walk through a few examples of how a user can apply our methods.

```python
from tests_main import *
from utils import proj, generate_penalty
import numpy as np

np.random.seed(1)

# Set parameters
n = 100
d = 50
k = 10
var = 1

# Generate data
X = np.random.multivariate_normal(np.zeros(d), np.eye(d), size=n)
X = (X - X.mean(axis=0)) / X.std(axis=0)
beta = np.zeros(d)
sample = np.random.choice(np.arange(k, d), 5, replace=False)
beta[sample] = np.random.choice([-1, 1], size=5) * 5
a = 0.6 / np.sqrt(k)
beta[0:k] = np.full(k, a)
y = np.random.multivariate_normal(X@beta, (var ** 2) * np.eye(n))
P_k = proj(X[:,k:])
y_hat = P_k @ y
sigma = np.linalg.norm(y - P_k@y)

"""
Below, we run the oracle and L-test. All tests assess the signifiance of the first k covariates.
"""
oracle_pval = oracle_test(y, X, k, beta[0:k] / np.linalg.norm(beta[0:k]))
L_pval = L_test(y, X, k)

"""
For precise p-values, users can either increase the number of Monte Carlo samples
used to compute the L-test p-value or run the efficient R-test, which does not use resampling.
"""

L_pval = L_test(y, X, k, MC=500)
R_pval = R_test(y, X, k)

"""
To run the tests with the same penalty parameter, users can generate the
penalty separately and then specify it as an input.
"""

u = np.random.randn(n - d + k)
u /= np.linalg.norm(u)
y_tilde = y_hat + sigma * V @ u
l, estimate = generate_penalty(y_tilde, X, k)
L_pval = L_test(y, X, k, penalty = l, point = estimate)
R_pval = R_test(y, X, k, penalty = l, point = estimate)
```

## Reproducing Figures
Most of the figures were generated by running code on a computing cluster with a SLURM job manager, while a few were generated from python scripts that can be run on a single computer. All code files can be found in the `reproduce` folder, and the folder `reproduce/scripts` contains the scripts needed to submit jobs to the cluster; some of the parameters may need to be adjusted, such as the partitions and memory. Sub-figures are referred to alphabetically from left to right and top to bottom in the corresponding figure.

1. **Power plots:** For Figures 2, 11, 12, 14, and 15, uncomment the code block corresponding to the sub-figure you want to generate in `compare_tests.py` and follow the comments in the file to adjust data structures as needed depending on the tests you need to run. Run this file 1000 times by submitting 250 jobs to the cluster with `scripts/run_tests.sh`. Then run `combine.py` with `scripts/run_combine.sh` to generate and save a csv file called `avg_powers.csv`. Run the file `viz.py` to generate the figure from the data in the csv file.

2. **Orthogonal design:** For Figures 3 and 13, uncomment the code block corresponding to the sub-figure you want to generate in `compare_tests.py` and follow the comments in the file to adjust data structures as needed depending on the tests you need to run. Enable orthogonality by passing `orthog=True` to `generate_design()`. For 3A and 13x, set `anti=True` when calling `generate_beta()`; for 3B and 13x, set `anti=False` when calling `generate_beta()`. Run this file 1000 times by submitting 250 jobs to the cluster with `scripts/run_tests.sh`. Then run `combine.py` with `scripts/run_combine.sh` to generate and save a csv file called `avg_powers.csv`. Run the file `viz.py` to generate the figure from the data in the csv file.

3. **Robustness:** For Figures 4, 16, 17, 18, and 19, run `robustness.py` 1000 times by submitting 250 jobs to the cluster with `scripts/run_robustness.sh`. Then run `combine_robustness.py` with `scripts/run_combine_robustness.sh` to generate and save a pkl file called `avg_errors.pkl`. Follow the comments in `viz.py` and then run the file to generate all of the sub-figures. 

4. **HIV drug data application:** For Figure 5, follow the comments in the file `HIV.py` to adjust the data structures as needed for the tests being run. Then run the file 16 times by submitting 16 jobs to the cluster with `scripts/run_HIV.sh` to generate and save 16 csv files, each containing p-values corresponding to one of the 16 regressions. Uncomment the appropriate code block in `combine_HIV.py` depending on which sub-figure you want to generate. Note that the directory in which the p-value csv files are stored may need to be updated from `p_vals`. For Figure 6, follow the comments in the file `HIV.py` to run the F-test, L-test with MC = 500, and R-test and then run the file 800 times by submitting 800 jobs to the cluster with `scripts/run_HIV.sh`. Then run the file `combine_HIV_MT.py` with `scripts/run_HIV_combine_MT.sh` to generate two csv files storing average powers and times. Repeat this process three more times, each time only running the L-test with MC = 5000, 50000, and 500000, respectively. Run the file `viz_MT.py` to generate the time and power plots from the eight csv files.

5. **Penalty choices:** For Figures 7 and 8, uncomment the code block corresponding to the sub-figure you want to generate in `compare_penalties.py` and follow the comments to run the desired tests. Run this file 1000 times by submitting 250 jobs to the cluster with `scripts/run_penalties.sh`. Then run `combine.py` with `scripts/run_combine.sh` to generate and save a csv file called `avg_powers.csv`. Run the file `viz.py` to generate the figure from the data in the csv file.

6. **Variability experiment:** For the left panel in Figure 8, modify `variability.py` to run the L-test with $r = 1$. Run the file 200,000 times by submitting 2000 jobs to the cluster with `scripts/run_var.sh`. Then run `combine_var.py` with `scripts/run_combine_var.sh` to obtain a csv file of means and a csv file of standard errors. Repeat these prior steps but changing $r = 5$ in `variability.py`. Run `viz_var.py` to combine the four csv files and obtain the plot. For the right panel in Figure 8, repeat this entire process but running the recentered test in `variability.py` instead.

8. **Visualizing $f^{-1}_{S^{(1:k)}}$ from Theorem C.7:** For Figure 9, run `viz_f_inv.py`. Follow the comments to generate the plots corresponding to both the low and high correlation regimes.

9. **P-value heatmaps:** For Figure 10, run `viz_pval_mass.py`. Follow the comments to generate the plots corresponding to both the low and high correlation regimes. 


## Citation

@article{DP-SS-LJ:2025,
  title={An alternative to the $F$-test with enhanced power in sparse linear models},
  author={Paulson, Danielle and Sengupta, Souhardya and Janson, Lucas},
  journal={arXiv preprint xxx},
  year={2025}
}
