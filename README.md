# Code repository for "The L-test: Increasing the Linear Model F-test's Power Under Sparsity Without Sacrificing Validity" by Paulson, Sengupta, and Janson (2025)

This repository contains the source code for implementing all of the testing procedures and reproducing all of the figures presented in the [paper](https://arxiv.org/abs/2406.18390). The L-test is a new procedure for testing the signifiance of a subset of covariates (i.e. $H_0: \beta_{1:k} = 0$) in a Gaussian linear model with $n \geq d$. Under the same assumptions as the classical F-test, the L-test delivers the exact same statistical guarantees while achieving higher power when the nuisance parameters $\beta_{-1:k}$ are sparse.

## Example of methods application
The file `tests_main.py` contains the main methods introduced in the paper, including the L-test and its Monte Carlo (MC) sampling free variant (MC-free), particularly useful for large-scale multiple testing settings. The file `utils.py` contains helper functions to implement these main methods, and `tests_support.py` contains additional tests considered in the paper. Below, we walk through a few examples of how a user can apply our methods.

```python
from tests_main import *
from utils import proj, generate_penalty
import numpy as np

np.random.seed(1)

# Set parameters
n = 100
d = 50
k = 10
var = 1

# Generate data
X = np.random.multivariate_normal(np.zeros(d), np.eye(d), size=n)
X = (X - X.mean(axis=0)) / X.std(axis=0)
beta = np.zeros(d)
sample = np.random.choice(np.arange(k, d), 5, replace=False)
beta[sample] = np.random.choice([-1, 1], size=5) * 5
a = 0.6 / np.sqrt(k)
beta[0:k] = np.full(k, a)
y = np.random.multivariate_normal(X@beta, (var ** 2) * np.eye(n))
P_k = proj(X[:,k:])
y_hat = P_k @ y
sigma = np.linalg.norm(y - P_k@y)

"""
Below, we run the L-test. All tests assess the signifiance of the first k covariates.
"""
L_pval = L_test(y, X, k)

"""
For precise p-values, users can either increase the number of Monte Carlo samples
used to compute the L-test p-value or run the MC-free test, which does not use resampling.
"""

L_pval = L_test(y, X, k, MC=500)
MCfree_pval = MC_free(y, X, k)

"""
To run the tests with the same penalty parameter and point estimate, users can generate these separately and then specify them as inputs.
"""

u = np.random.randn(n - d + k)
u /= np.linalg.norm(u)
y_tilde = y_hat + sigma * V @ u
l, estimate = generate_penalty(y_tilde, X, k)
L_pval = L_test(y, X, k, penalty = l, point = estimate)
MCfree_pval = MC_free(y, X, k, penalty = l, point = estimate)
```

## Reproducing Figures
Most of the figures were generated by running code on a computing cluster with a SLURM job manager, while a few were generated from python scripts that can be run on a single computer. All code files can be found in the `reproduce` folder, and the folder `reproduce/scripts` contains the scripts needed to submit jobs to the cluster; some of the parameters may need to be adjusted, such as the partitions and memory. Sub-figures are referred to alphabetically from left to right and top to bottom in the corresponding figure.

1. **Power plots:** For Figures 2, 12, 13, 15, 16, uncomment the code block corresponding to the sub-figure you want to generate in `compare_tests.py` and follow the comments in the file to adjust data structures as needed depending on the tests you need to run. For Figure 2, the `utilities.R` and `l_testing.R` files from the [Sengupta et al. 2025 code repository](https://github.com/SSouhardya/l-test) need to be in the same directory in order to run the $\text{Bonf-}\ell$ test. Only for Figure 15E, set `anti=True` when calling `generate_beta()`. Run this file 1000 times by submitting 250 jobs to the cluster with `scripts/run_tests.sh`. Then run `combine.py` with `scripts/run_combine.sh` to generate and save a csv file called `avg_powers.csv`. Run the file `viz.py` to generate the figure from the data in the csv file. Note that some adjustments may need to be made to `viz.py` to replicate the exact figure formatting (ie. legend names).

2. **Orthogonal design:** For Figures 3 and 14, uncomment the code block corresponding to the sub-figure you want to generate in `compare_tests.py` and follow the comments in the file to adjust data structures as needed depending on the tests you need to run. Enable orthogonality by passing `orthog=True` to `generate_design()`. For 3B, set `anti=True` when calling `generate_beta()`; for 3C, set `anti=False` when calling `generate_beta()`. Run this file 1000 times by submitting 250 jobs to the cluster with `scripts/run_tests.sh`. Then run `combine.py` with `scripts/run_combine.sh` to generate and save a csv file called `avg_powers.csv`. Run the file `viz.py` to generate the figure from the data in the csv file.

3. **Robustness:** For Figures 4 and 17-24, run `robustness.py` 1000 times by submitting 250 jobs to the cluster with `scripts/run_robustness.sh`. Then run `combine_robustness.py` with `scripts/run_combine_robustness.sh` to generate and save a pkl file called `avg_errors.pkl`. Follow the comments in `viz.py` and then run the file to generate all of the sub-figures. For Figures 21-24, perform the same process but follow the comments in `robustness.py` to set $\rho = 0.5$.

4. **HIV drug data application:** For Figure 5, follow the comments in the file `HIV.py` to adjust the data structures as needed for the tests being run. Then run the file 16 times by submitting 16 jobs to the cluster with `scripts/run_HIV.sh` to generate and save 16 csv files, each containing p-values corresponding to one of the 16 regressions. Uncomment the appropriate code block in `combine_HIV.py` depending on which sub-figure you want to generate. Note that the directory in which the p-value csv files are stored may need to be updated from `p_vals`. For Figure 6, follow the comments in the file `HIV.py` to run the F-test, L-test with MC = 500, and R-test and then run the file 800 times by submitting 800 jobs to the cluster with `scripts/run_HIV.sh`. Then run the file `combine_HIV_MT.py` with `scripts/run_HIV_combine_MT.sh` to generate two csv files storing average powers and times. Repeat this process three more times, each time only running the L-test with MC = 5000, 50000, and 500000, respectively. Run the file `viz_MT.py` to generate the time and power plots from the eight csv files.

5. **Penalty choices:** For Figures 7 and 9, uncomment the code block corresponding to the sub-figure you want to generate in `compare_penalties.py` and follow the comments to run the desired tests. Run this file 1000 times by submitting 250 jobs to the cluster with `scripts/run_penalties.sh`. Then run `combine.py` with `scripts/run_combine.sh` to generate and save a csv file called `avg_powers.csv`. Run the file `viz.py` to generate the figure from the data in the csv file.

6. **Variability experiment:** For the left panel in Figure 8, modify `variability.py` to run the L-test with $r = 1$. Run the file 200,000 times by submitting 2000 jobs to the cluster with `scripts/run_var.sh`. Then run `combine_var.py` with `scripts/run_combine_var.sh` to obtain a csv file of means and a csv file of standard errors. Repeat these prior steps but changing $r = 5$ in `variability.py`. Run `viz_var.py` to combine the four csv files and obtain the plot. For the right panel in Figure 8, repeat this entire process but running the MC-free test in `variability.py` instead.

8. **Visualizing $f^{-1}_{S^{(1:k)}}$ from Theorem C.7:** For Figure 10, run `viz_f_inv.py`. Follow the comments to generate the plots corresponding to both the low and high correlation regimes.

9. **P-value heatmaps:** For Figure 11, run `viz_pval_mass.py`. Follow the comments to generate the plots corresponding to both the low and high correlation regimes. 


## Citation

@article{DP-SS-LJ:2025,
  title={The L-test: Increasing the Linear Model F-test's Power Under Sparsity Without Sacrificing Validity},
  author={Paulson, Danielle and Sengupta, Souhardya and Janson, Lucas},
  journal={arXiv preprint xxx},
  year={2025}
}
